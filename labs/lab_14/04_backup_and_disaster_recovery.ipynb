{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 14 - Part 4: Backup and Disaster Recovery\n",
    "\n",
    "## Overview\n",
    "This notebook covers enterprise backup and disaster recovery including:\n",
    "- Backup automation system\n",
    "- Database backup procedures\n",
    "- Disaster recovery planning\n",
    "- Backup verification\n",
    "\n",
    "**Duration:** 10 minutes  \n",
    "**Prerequisites:** Parts 1, 2, and 3 completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Import necessary modules and check for required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Check for scheduling library\n",
    "try:\n",
    "    import schedule\n",
    "    SCHEDULE_AVAILABLE = True\n",
    "    print(\"✓ Schedule library available\")\n",
    "except ImportError:\n",
    "    SCHEDULE_AVAILABLE = False\n",
    "    print(\"⚠️ Schedule not available - using basic scheduling\")\n",
    "\n",
    "# Mock prod_config if not available\n",
    "try:\n",
    "    prod_config\n",
    "    print(\"✓ Production config loaded\")\n",
    "except NameError:\n",
    "    class MockConfig:\n",
    "        def get_config(self, env):\n",
    "            return {\n",
    "                \"neo4j_uri\": \"bolt://localhost:7687\",\n",
    "                \"neo4j_user\": \"neo4j\",\n",
    "                \"neo4j_password\": \"password\"\n",
    "            }\n",
    "    prod_config = MockConfig()\n",
    "    print(\"⚠️ Using mock configuration\")\n",
    "\n",
    "# Mock logging_system if not available\n",
    "try:\n",
    "    logging_system\n",
    "    print(\"✓ Logging system loaded\")\n",
    "except NameError:\n",
    "    import logging\n",
    "    class MockLoggingSystem:\n",
    "        def __init__(self):\n",
    "            self.app_logger = logging.getLogger('app')\n",
    "        def log_user_action(self, *args, **kwargs):\n",
    "            pass\n",
    "    logging_system = MockLoggingSystem()\n",
    "    print(\"⚠️ Using mock logging system\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup Automation System\n",
    "\n",
    "Create a comprehensive backup system with automated scheduling and retention policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackupAutomationSystem:\n",
    "    \"\"\"Automated backup and disaster recovery system\"\"\"\n",
    "    \n",
    "    def __init__(self, neo4j_config: dict):\n",
    "        self.neo4j_config = neo4j_config\n",
    "        self.backup_directory = \"/tmp/neo4j_backups\"  # Using /tmp for demo\n",
    "        self.retention_days = 30\n",
    "        self.backup_schedule = \"daily\"\n",
    "        \n",
    "        # Create backup directory\n",
    "        os.makedirs(self.backup_directory, exist_ok=True)\n",
    "        \n",
    "        # Initialize backup history\n",
    "        self.backup_history = []\n",
    "    \n",
    "    def create_database_backup(self) -> dict:\n",
    "        \"\"\"Create comprehensive database backup\"\"\"\n",
    "        try:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            backup_name = f\"neo4j_backup_{timestamp}\"\n",
    "            backup_path = os.path.join(self.backup_directory, backup_name)\n",
    "            \n",
    "            # Create backup directory\n",
    "            os.makedirs(backup_path, exist_ok=True)\n",
    "            \n",
    "            print(f\"Creating database backup: {backup_name}\")\n",
    "            \n",
    "            # Simulate backup process (in real environment, this would execute the actual command)\n",
    "            backup_info = {\n",
    "                'backup_id': backup_name,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'status': 'completed',\n",
    "                'backup_path': backup_path,\n",
    "                'size_mb': 250.5,  # Simulated size\n",
    "                'duration_seconds': 45.2,\n",
    "                'database_state': {\n",
    "                    'nodes': 850,\n",
    "                    'relationships': 1100,\n",
    "                    'labels': 15,\n",
    "                    'relationship_types': 12\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Copy application configuration\n",
    "            self._backup_application_config(backup_path)\n",
    "            \n",
    "            # Backup security configurations\n",
    "            self._backup_security_config(backup_path)\n",
    "            \n",
    "            # Record backup in history\n",
    "            self.backup_history.append(backup_info)\n",
    "            \n",
    "            # Clean old backups\n",
    "            self._cleanup_old_backups()\n",
    "            \n",
    "            logging_system.app_logger.info(f\"Backup completed successfully: {backup_name}\")\n",
    "            \n",
    "            return backup_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_info = {\n",
    "                'backup_id': f\"failed_{timestamp}\",\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'status': 'failed',\n",
    "                'error': str(e)\n",
    "            }\n",
    "            \n",
    "            logging_system.app_logger.error(f\"Backup failed: {str(e)}\")\n",
    "            return error_info\n",
    "    \n",
    "    def _backup_application_config(self, backup_path: str):\n",
    "        \"\"\"Backup application configuration files\"\"\"\n",
    "        config_backup_path = os.path.join(backup_path, \"application_config\")\n",
    "        os.makedirs(config_backup_path, exist_ok=True)\n",
    "        \n",
    "        # Save production configuration\n",
    "        config_file = os.path.join(config_backup_path, \"production_config.json\")\n",
    "        try:\n",
    "            config_data = prod_config.get_config(\"production\")\n",
    "            with open(config_file, 'w') as f:\n",
    "                json.dump(config_data, f, indent=2)\n",
    "        except:\n",
    "            pass  # Skip if config not available\n",
    "        \n",
    "        # Save environment variables (sanitized)\n",
    "        env_file = os.path.join(config_backup_path, \"environment.json\")\n",
    "        sanitized_env = {k: v for k, v in os.environ.items() \n",
    "                        if not any(secret in k.lower() for secret in ['password', 'key', 'secret', 'token'])}\n",
    "        \n",
    "        with open(env_file, 'w') as f:\n",
    "            json.dump(sanitized_env, f, indent=2)\n",
    "    \n",
    "    def _backup_security_config(self, backup_path: str):\n",
    "        \"\"\"Backup security configuration (encrypted)\"\"\"\n",
    "        security_backup_path = os.path.join(backup_path, \"security_config\")\n",
    "        os.makedirs(security_backup_path, exist_ok=True)\n",
    "        \n",
    "        # Backup user roles and permissions (passwords excluded)\n",
    "        users_backup = {}\n",
    "        try:\n",
    "            # Try to access auth_system if available\n",
    "            if 'auth_system' in globals():\n",
    "                for user_id, user_data in auth_system.users.items():\n",
    "                    users_backup[user_id] = {\n",
    "                        'user_id': user_data['user_id'],\n",
    "                        'username': user_data['username'],\n",
    "                        'role': user_data['role'],\n",
    "                        'permissions': user_data['permissions'],\n",
    "                        'email': user_data['email'],\n",
    "                        'department': user_data.get('department'),\n",
    "                        'created_at': user_data['created_at'],\n",
    "                        'active': user_data['active']\n",
    "                    }\n",
    "        except:\n",
    "            users_backup = {'note': 'User data not available during backup'}\n",
    "        \n",
    "        users_file = os.path.join(security_backup_path, \"users_config.json\")\n",
    "        with open(users_file, 'w') as f:\n",
    "            json.dump(users_backup, f, indent=2)\n",
    "    \n",
    "    def _cleanup_old_backups(self):\n",
    "        \"\"\"Remove backups older than retention period\"\"\"\n",
    "        cutoff_date = datetime.now() - timedelta(days=self.retention_days)\n",
    "        \n",
    "        # Filter backup history\n",
    "        self.backup_history = [\n",
    "            backup for backup in self.backup_history\n",
    "            if datetime.fromisoformat(backup['timestamp']) >= cutoff_date\n",
    "        ]\n",
    "        \n",
    "        # Remove old backup directories\n",
    "        try:\n",
    "            for item in os.listdir(self.backup_directory):\n",
    "                item_path = os.path.join(self.backup_directory, item)\n",
    "                if os.path.isdir(item_path):\n",
    "                    # Parse timestamp from directory name\n",
    "                    try:\n",
    "                        timestamp_str = item.split('_')[-2] + '_' + item.split('_')[-1]\n",
    "                        backup_date = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')\n",
    "                        \n",
    "                        if backup_date < cutoff_date:\n",
    "                            shutil.rmtree(item_path)\n",
    "                            print(f\"Removed old backup: {item}\")\n",
    "                    except (ValueError, IndexError):\n",
    "                        continue\n",
    "        except Exception as e:\n",
    "            logging_system.app_logger.warning(f\"Error cleaning old backups: {e}\")\n",
    "    \n",
    "    def restore_from_backup(self, backup_id: str) -> dict:\n",
    "        \"\"\"Restore database from backup\"\"\"\n",
    "        try:\n",
    "            # Find backup in history\n",
    "            backup_info = None\n",
    "            for backup in self.backup_history:\n",
    "                if backup['backup_id'] == backup_id:\n",
    "                    backup_info = backup\n",
    "                    break\n",
    "            \n",
    "            if not backup_info:\n",
    "                raise ValueError(f\"Backup not found: {backup_id}\")\n",
    "            \n",
    "            backup_path = backup_info['backup_path']\n",
    "            \n",
    "            if not os.path.exists(backup_path):\n",
    "                raise ValueError(f\"Backup files not found: {backup_path}\")\n",
    "            \n",
    "            print(f\"Restoring from backup: {backup_id}\")\n",
    "            \n",
    "            # Simulate restore process\n",
    "            restore_info = {\n",
    "                'restore_id': f\"restore_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "                'backup_id': backup_id,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'status': 'completed',\n",
    "                'duration_seconds': 120.5,\n",
    "                'restored_state': backup_info['database_state']\n",
    "            }\n",
    "            \n",
    "            logging_system.app_logger.info(f\"Restore completed successfully from backup: {backup_id}\")\n",
    "            \n",
    "            return restore_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            restore_info = {\n",
    "                'restore_id': f\"restore_failed_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "                'backup_id': backup_id,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'status': 'failed',\n",
    "                'error': str(e)\n",
    "            }\n",
    "            \n",
    "            logging_system.app_logger.error(f\"Restore failed: {str(e)}\")\n",
    "            return restore_info\n",
    "    \n",
    "    def schedule_automated_backups(self):\n",
    "        \"\"\"Schedule automated backup jobs with fallback\"\"\"\n",
    "        if SCHEDULE_AVAILABLE:\n",
    "            if self.backup_schedule == \"daily\":\n",
    "                schedule.every().day.at(\"02:00\").do(self.create_database_backup)\n",
    "            elif self.backup_schedule == \"hourly\":\n",
    "                schedule.every().hour.do(self.create_database_backup)\n",
    "            \n",
    "            print(f\"✓ Automated backups scheduled: {self.backup_schedule}\")\n",
    "        else:\n",
    "            print(f\"⚠️ Schedule library not available - backup scheduling simulated: {self.backup_schedule}\")\n",
    "    \n",
    "    def get_backup_status(self) -> dict:\n",
    "        \"\"\"Get backup system status\"\"\"\n",
    "        return {\n",
    "            'total_backups': len(self.backup_history),\n",
    "            'latest_backup': self.backup_history[-1] if self.backup_history else None,\n",
    "            'backup_directory': self.backup_directory,\n",
    "            'retention_days': self.retention_days,\n",
    "            'schedule': self.backup_schedule,\n",
    "            'disk_usage': self._get_backup_disk_usage()\n",
    "        }\n",
    "    \n",
    "    def _get_backup_disk_usage(self) -> dict:\n",
    "        \"\"\"Calculate backup directory disk usage\"\"\"\n",
    "        total_size = 0\n",
    "        file_count = 0\n",
    "        \n",
    "        try:\n",
    "            for root, dirs, files in os.walk(self.backup_directory):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    if os.path.exists(file_path):\n",
    "                        total_size += os.path.getsize(file_path)\n",
    "                        file_count += 1\n",
    "        except Exception as e:\n",
    "            logging_system.app_logger.warning(f\"Error calculating backup disk usage: {e}\")\n",
    "        \n",
    "        return {\n",
    "            'total_size_mb': round(total_size / (1024 * 1024), 2),\n",
    "            'file_count': file_count\n",
    "        }\n",
    "\n",
    "# Initialize backup system\n",
    "backup_system = BackupAutomationSystem(prod_config.get_config(\"production\"))\n",
    "print(\"✓ Backup automation system configured\")\n",
    "print(f\"📁 Backup directory: {backup_system.backup_directory}\")\n",
    "print(f\"📅 Retention period: {backup_system.retention_days} days\")\n",
    "print(f\"⏰ Schedule: {backup_system.backup_schedule}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Database Backup\n",
    "\n",
    "Create a comprehensive backup of the database and configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"💾 Creating Database Backup...\\n\")\n",
    "\n",
    "# Create backup\n",
    "backup_result = backup_system.create_database_backup()\n",
    "\n",
    "if backup_result['status'] == 'completed':\n",
    "    print(\"✅ Backup completed successfully!\\n\")\n",
    "    print(f\"Backup ID: {backup_result['backup_id']}\")\n",
    "    print(f\"Timestamp: {backup_result['timestamp']}\")\n",
    "    print(f\"Backup Path: {backup_result['backup_path']}\")\n",
    "    print(f\"Size: {backup_result['size_mb']} MB\")\n",
    "    print(f\"Duration: {backup_result['duration_seconds']} seconds\")\n",
    "    print(f\"\\nDatabase State:\")\n",
    "    for key, value in backup_result['database_state'].items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(f\"❌ Backup failed: {backup_result.get('error', 'Unknown error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Multiple Backups\n",
    "\n",
    "Create several backups to simulate a backup history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📦 Creating Multiple Backups...\\n\")\n",
    "\n",
    "import time\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"Creating backup {i+1}/3...\")\n",
    "    result = backup_system.create_database_backup()\n",
    "    if result['status'] == 'completed':\n",
    "        print(f\"  ✓ {result['backup_id']}\")\n",
    "    time.sleep(1)  # Small delay between backups\n",
    "\n",
    "print(f\"\\n✅ Created {len(backup_system.backup_history)} backups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Backup Status\n",
    "\n",
    "Display comprehensive backup system status and history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📊 Backup System Status\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "status = backup_system.get_backup_status()\n",
    "\n",
    "print(f\"Total Backups: {status['total_backups']}\")\n",
    "print(f\"Backup Directory: {status['backup_directory']}\")\n",
    "print(f\"Retention Period: {status['retention_days']} days\")\n",
    "print(f\"Schedule: {status['schedule']}\")\n",
    "print(f\"\\nDisk Usage:\")\n",
    "print(f\"  Total Size: {status['disk_usage']['total_size_mb']} MB\")\n",
    "print(f\"  File Count: {status['disk_usage']['file_count']}\")\n",
    "\n",
    "if status['latest_backup']:\n",
    "    latest = status['latest_backup']\n",
    "    print(f\"\\nLatest Backup:\")\n",
    "    print(f\"  ID: {latest['backup_id']}\")\n",
    "    print(f\"  Timestamp: {latest['timestamp']}\")\n",
    "    print(f\"  Status: {latest['status']}\")\n",
    "    print(f\"  Size: {latest['size_mb']} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List All Backups\n",
    "\n",
    "Display detailed information about all available backups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📋 Backup History\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "if backup_system.backup_history:\n",
    "    for idx, backup in enumerate(backup_system.backup_history, 1):\n",
    "        print(f\"Backup #{idx}:\")\n",
    "        print(f\"  ID: {backup['backup_id']}\")\n",
    "        print(f\"  Time: {backup['timestamp']}\")\n",
    "        print(f\"  Status: {backup['status']}\")\n",
    "        print(f\"  Size: {backup['size_mb']} MB\")\n",
    "        print(f\"  Duration: {backup['duration_seconds']}s\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No backups found\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Backup Restoration\n",
    "\n",
    "Test the restoration process from a backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔄 Testing Backup Restoration...\\n\")\n",
    "\n",
    "if backup_system.backup_history:\n",
    "    # Get the latest backup\n",
    "    latest_backup = backup_system.backup_history[-1]\n",
    "    backup_id = latest_backup['backup_id']\n",
    "    \n",
    "    print(f\"Restoring from backup: {backup_id}\\n\")\n",
    "    \n",
    "    # Perform restore\n",
    "    restore_result = backup_system.restore_from_backup(backup_id)\n",
    "    \n",
    "    if restore_result['status'] == 'completed':\n",
    "        print(\"✅ Restore completed successfully!\\n\")\n",
    "        print(f\"Restore ID: {restore_result['restore_id']}\")\n",
    "        print(f\"Backup ID: {restore_result['backup_id']}\")\n",
    "        print(f\"Timestamp: {restore_result['timestamp']}\")\n",
    "        print(f\"Duration: {restore_result['duration_seconds']} seconds\")\n",
    "        print(f\"\\nRestored State:\")\n",
    "        for key, value in restore_result['restored_state'].items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"❌ Restore failed: {restore_result.get('error', 'Unknown error')}\")\n",
    "else:\n",
    "    print(\"⚠️ No backups available to restore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedule Automated Backups\n",
    "\n",
    "Configure automated backup scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"⏰ Configuring Automated Backup Schedule...\\n\")\n",
    "\n",
    "# Schedule automated backups\n",
    "backup_system.schedule_automated_backups()\n",
    "\n",
    "print(f\"\\n✅ Automated backups configured\")\n",
    "print(f\"\\n📅 Backup Schedule Details:\")\n",
    "print(f\"  Frequency: {backup_system.backup_schedule}\")\n",
    "print(f\"  Time: 02:00 UTC (for daily backups)\")\n",
    "print(f\"  Retention: {backup_system.retention_days} days\")\n",
    "print(f\"  Directory: {backup_system.backup_directory}\")\n",
    "\n",
    "print(f\"\\n📝 Backup Best Practices:\")\n",
    "print(f\"  ✓ Daily backups at low-traffic times\")\n",
    "print(f\"  ✓ Retain backups for compliance period (30 days)\")\n",
    "print(f\"  ✓ Store backups in separate physical location\")\n",
    "print(f\"  ✓ Test restoration procedures regularly\")\n",
    "print(f\"  ✓ Monitor backup success/failure\")\n",
    "print(f\"  ✓ Encrypt backup data at rest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disaster Recovery Planning\n",
    "\n",
    "Document disaster recovery procedures and objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_recovery_plan = {\n",
    "    \"Recovery Time Objective (RTO)\": \"15 minutes\",\n",
    "    \"Recovery Point Objective (RPO)\": \"5 minutes\",\n",
    "    \"Backup Frequency\": \"Daily at 02:00 UTC\",\n",
    "    \"Backup Retention\": \"30 days\",\n",
    "    \"Hot Standby\": \"Yes - Secondary data center\",\n",
    "    \"Automatic Failover\": \"Enabled\",\n",
    "    \"Replication Lag\": \"<100ms\",\n",
    "    \"Recovery Procedures\": [\n",
    "        \"1. Assess disaster scope and impact\",\n",
    "        \"2. Activate disaster recovery team\",\n",
    "        \"3. Switch to hot standby if available\",\n",
    "        \"4. If standby unavailable, restore from latest backup\",\n",
    "        \"5. Verify data integrity post-restore\",\n",
    "        \"6. Update DNS and routing if needed\",\n",
    "        \"7. Perform smoke tests\",\n",
    "        \"8. Monitor system stability\",\n",
    "        \"9. Notify stakeholders of recovery completion\"\n",
    "    ],\n",
    "    \"Testing Schedule\": \"Quarterly disaster recovery drills\",\n",
    "    \"Contact List\": [\n",
    "        \"Platform Engineering Lead\",\n",
    "        \"Database Administrator\",\n",
    "        \"Security Team\",\n",
    "        \"Executive Management\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"🚨 DISASTER RECOVERY PLAN\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "for key, value in disaster_recovery_plan.items():\n",
    "    if isinstance(value, list):\n",
    "        print(f\"{key}:\")\n",
    "        for item in value:\n",
    "            print(f\"  {item}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save disaster recovery plan\n",
    "dr_plan_file = os.path.join(backup_system.backup_directory, \"disaster_recovery_plan.json\")\n",
    "with open(dr_plan_file, 'w') as f:\n",
    "    json.dump(disaster_recovery_plan, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Disaster recovery plan saved to: {dr_plan_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "In this notebook, you've:\n",
    "1. ✅ Implemented automated backup system\n",
    "2. ✅ Created comprehensive database backups\n",
    "3. ✅ Tested backup restoration procedures\n",
    "4. ✅ Configured retention policies\n",
    "5. ✅ Documented disaster recovery plan\n",
    "\n",
    "**Backup and DR Best Practices:**\n",
    "- Follow the 3-2-1 rule: 3 copies, 2 different media, 1 offsite\n",
    "- Test restoration procedures regularly (at least quarterly)\n",
    "- Automate backups to ensure consistency\n",
    "- Monitor backup success/failure with alerts\n",
    "- Document RTO and RPO objectives clearly\n",
    "- Encrypt backups at rest and in transit\n",
    "- Keep disaster recovery procedures up to date\n",
    "- Train team members on recovery procedures\n",
    "\n",
    "**Recovery Metrics:**\n",
    "- **RTO (Recovery Time Objective):** 15 minutes\n",
    "- **RPO (Recovery Point Objective):** 5 minutes\n",
    "- **Backup Frequency:** Daily\n",
    "- **Retention Period:** 30 days\n",
    "\n",
    "**Next Steps:** Proceed to notebook 05 for CI/CD and Container Deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
