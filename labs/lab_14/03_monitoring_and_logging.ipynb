{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 14 - Part 3: Monitoring and Logging\n",
    "\n",
    "## Overview\n",
    "This notebook covers production monitoring and observability including:\n",
    "- Production monitoring system\n",
    "- Prometheus metrics collection\n",
    "- System metrics (CPU, memory)\n",
    "- Neo4j database metrics\n",
    "- Logging and audit system\n",
    "\n",
    "**Duration:** 10 minutes  \n",
    "**Prerequisites:** Parts 1 and 2 completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Import necessary modules and check for monitoring libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Check for monitoring libraries\n",
    "try:\n",
    "    from prometheus_client import Counter, Histogram, Gauge, start_http_server\n",
    "    PROMETHEUS_AVAILABLE = True\n",
    "    print(\"✓ Prometheus client available\")\n",
    "except ImportError:\n",
    "    PROMETHEUS_AVAILABLE = False\n",
    "    print(\"⚠️ Prometheus client not available - metrics will be simulated\")\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "    PSUTIL_AVAILABLE = True\n",
    "    print(\"✓ Psutil library available\")\n",
    "except ImportError:\n",
    "    PSUTIL_AVAILABLE = False\n",
    "    print(\"⚠️ Psutil not available - system metrics will be simulated\")\n",
    "\n",
    "try:\n",
    "    from neo4j import GraphDatabase\n",
    "    NEO4J_AVAILABLE = True\n",
    "    print(\"✓ Neo4j driver available\")\n",
    "except ImportError:\n",
    "    NEO4J_AVAILABLE = False\n",
    "    print(\"⚠️ Neo4j driver not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Monitoring System\n",
    "\n",
    "Create a comprehensive monitoring system with Prometheus metrics and health checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionMonitoringSystem:\n",
    "    \"\"\"Comprehensive monitoring system for production deployment\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize Prometheus metrics with fallback\n",
    "        if PROMETHEUS_AVAILABLE:\n",
    "            self.request_count = Counter('neo4j_app_requests_total', 'Total app requests', ['method', 'endpoint'])\n",
    "            self.request_duration = Histogram('neo4j_app_request_duration_seconds', 'Request duration')\n",
    "            self.active_connections = Gauge('neo4j_app_active_connections', 'Active database connections')\n",
    "            self.error_count = Counter('neo4j_app_errors_total', 'Total errors', ['error_type'])\n",
    "            \n",
    "            # System metrics\n",
    "            self.cpu_usage = Gauge('system_cpu_usage_percent', 'CPU usage percentage')\n",
    "            self.memory_usage = Gauge('system_memory_usage_percent', 'Memory usage percentage')\n",
    "            self.disk_usage = Gauge('system_disk_usage_percent', 'Disk usage percentage')\n",
    "            \n",
    "            # Neo4j specific metrics\n",
    "            self.neo4j_query_count = Counter('neo4j_queries_total', 'Total Neo4j queries', ['query_type'])\n",
    "            self.neo4j_query_duration = Histogram('neo4j_query_duration_seconds', 'Neo4j query duration')\n",
    "            self.neo4j_connection_errors = Counter('neo4j_connection_errors_total', 'Neo4j connection errors')\n",
    "            \n",
    "            # Health status\n",
    "            self.service_health = Gauge('service_health_status', 'Service health status (1=healthy, 0=unhealthy)')\n",
    "            \n",
    "            # Start metrics server\n",
    "            try:\n",
    "                start_http_server(9090)\n",
    "                print(\"✓ Prometheus metrics server started on port 9090\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Could not start Prometheus server: {e}\")\n",
    "        else:\n",
    "            # Mock metrics for fallback\n",
    "            self.metrics_data = {\n",
    "                'requests_total': 0,\n",
    "                'errors_total': 0,\n",
    "                'active_connections': 0,\n",
    "                'service_health': 1\n",
    "            }\n",
    "            print(\"⚠️ Using simulated metrics - install prometheus-client for production monitoring\")\n",
    "    \n",
    "    def collect_system_metrics(self):\n",
    "        \"\"\"Collect system performance metrics with fallback\"\"\"\n",
    "        try:\n",
    "            if PSUTIL_AVAILABLE:\n",
    "                # Real system metrics\n",
    "                cpu_percent = psutil.cpu_percent(interval=1)\n",
    "                memory = psutil.virtual_memory()\n",
    "                disk = psutil.disk_usage('/')\n",
    "                disk_percent = (disk.used / disk.total) * 100\n",
    "                \n",
    "                if PROMETHEUS_AVAILABLE:\n",
    "                    self.cpu_usage.set(cpu_percent)\n",
    "                    self.memory_usage.set(memory.percent)\n",
    "                    self.disk_usage.set(disk_percent)\n",
    "                \n",
    "                return {\n",
    "                    'cpu_percent': cpu_percent,\n",
    "                    'memory_percent': memory.percent,\n",
    "                    'disk_percent': disk_percent,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "            else:\n",
    "                # Simulated metrics\n",
    "                import random\n",
    "                cpu_percent = random.uniform(15, 45)\n",
    "                memory_percent = random.uniform(40, 70)\n",
    "                disk_percent = random.uniform(25, 60)\n",
    "                \n",
    "                return {\n",
    "                    'cpu_percent': cpu_percent,\n",
    "                    'memory_percent': memory_percent,\n",
    "                    'disk_percent': disk_percent,\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'simulated': True\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error collecting system metrics: {e}\")\n",
    "            return {\n",
    "                'cpu_percent': 0,\n",
    "                'memory_percent': 0,\n",
    "                'disk_percent': 0,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    def collect_neo4j_metrics(self, driver):\n",
    "        \"\"\"Collect Neo4j database metrics\"\"\"\n",
    "        try:\n",
    "            with driver.session() as session:\n",
    "                metrics = {}\n",
    "                \n",
    "                # Execute queries safely\n",
    "                try:\n",
    "                    result = session.run(\"MATCH (n) RETURN count(n) as node_count\")\n",
    "                    metrics['node_count'] = result.single()['node_count']\n",
    "                except:\n",
    "                    metrics['node_count'] = 0\n",
    "                \n",
    "                try:\n",
    "                    result = session.run(\"MATCH ()-[r]->() RETURN count(r) as rel_count\")\n",
    "                    metrics['relationship_count'] = result.single()['rel_count']\n",
    "                except:\n",
    "                    metrics['relationship_count'] = 0\n",
    "                \n",
    "                # Test query performance\n",
    "                start_time = time.time()\n",
    "                session.run(\"RETURN 1\").consume()\n",
    "                query_time = time.time() - start_time\n",
    "                \n",
    "                metrics.update({\n",
    "                    'query_response_time': query_time,\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'database_status': 'healthy' if query_time < 1.0 else 'degraded'\n",
    "                })\n",
    "                \n",
    "                return metrics\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error collecting Neo4j metrics: {e}\")\n",
    "            if PROMETHEUS_AVAILABLE:\n",
    "                self.neo4j_connection_errors.inc()\n",
    "            return {'database_status': 'unhealthy', 'error': str(e)}\n",
    "    \n",
    "    def generate_health_report(self, driver):\n",
    "        \"\"\"Generate comprehensive health report\"\"\"\n",
    "        try:\n",
    "            system_metrics = self.collect_system_metrics()\n",
    "            neo4j_metrics = self.collect_neo4j_metrics(driver)\n",
    "            \n",
    "            # Determine overall health\n",
    "            health_status = 1  # healthy\n",
    "            alerts = []\n",
    "            \n",
    "            # System health checks\n",
    "            if system_metrics.get('cpu_percent', 0) > 80:\n",
    "                health_status = 0\n",
    "                alerts.append({\n",
    "                    'severity': 'critical',\n",
    "                    'message': f\"High CPU usage: {system_metrics['cpu_percent']:.1f}%\"\n",
    "                })\n",
    "            \n",
    "            if system_metrics.get('memory_percent', 0) > 85:\n",
    "                health_status = 0\n",
    "                alerts.append({\n",
    "                    'severity': 'critical',\n",
    "                    'message': f\"High memory usage: {system_metrics['memory_percent']:.1f}%\"\n",
    "                })\n",
    "            \n",
    "            if system_metrics.get('disk_percent', 0) > 90:\n",
    "                health_status = 0\n",
    "                alerts.append({\n",
    "                    'severity': 'critical',\n",
    "                    'message': f\"High disk usage: {system_metrics['disk_percent']:.1f}%\"\n",
    "                })\n",
    "            \n",
    "            # Database health checks\n",
    "            if neo4j_metrics.get('database_status') != 'healthy':\n",
    "                health_status = 0\n",
    "                alerts.append({\n",
    "                    'severity': 'critical',\n",
    "                    'message': f\"Database unhealthy: {neo4j_metrics.get('error', 'Unknown error')}\"\n",
    "                })\n",
    "            \n",
    "            if neo4j_metrics.get('query_response_time', 0) > 0.5:\n",
    "                alerts.append({\n",
    "                    'severity': 'warning',\n",
    "                    'message': f\"Slow query response: {neo4j_metrics['query_response_time']:.3f}s\"\n",
    "                })\n",
    "            \n",
    "            if PROMETHEUS_AVAILABLE:\n",
    "                self.service_health.set(health_status)\n",
    "            \n",
    "            return {\n",
    "                'overall_health': 'healthy' if health_status == 1 else 'unhealthy',\n",
    "                'system_metrics': system_metrics,\n",
    "                'database_metrics': neo4j_metrics,\n",
    "                'alerts': alerts,\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating health report: {e}\")\n",
    "            return {\n",
    "                'overall_health': 'unhealthy',\n",
    "                'error': str(e),\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "\n",
    "# Initialize monitoring system\n",
    "monitoring_system = ProductionMonitoringSystem()\n",
    "print(\"✓ Production monitoring system initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test System Metrics Collection\n",
    "\n",
    "Collect and display current system metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📊 Collecting System Metrics...\\n\")\n",
    "\n",
    "metrics = monitoring_system.collect_system_metrics()\n",
    "\n",
    "print(f\"CPU Usage: {metrics['cpu_percent']:.2f}%\")\n",
    "print(f\"Memory Usage: {metrics['memory_percent']:.2f}%\")\n",
    "print(f\"Disk Usage: {metrics['disk_percent']:.2f}%\")\n",
    "print(f\"Timestamp: {metrics['timestamp']}\")\n",
    "\n",
    "if metrics.get('simulated'):\n",
    "    print(\"\\n⚠️ Note: Metrics are simulated (install psutil for real metrics)\")\n",
    "\n",
    "print(\"\\n✅ System metrics collected successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging and Audit System\n",
    "\n",
    "Implement enterprise logging with audit trail capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionLoggingSystem:\n",
    "    \"\"\"Enterprise logging and audit system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Configure logging\n",
    "        self.setup_logging()\n",
    "        self.audit_log = []\n",
    "        self.max_audit_entries = 10000\n",
    "    \n",
    "    def setup_logging(self):\n",
    "        \"\"\"Configure production logging\"\"\"\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Create specialized loggers\n",
    "        self.app_logger = logging.getLogger('insurance_app')\n",
    "        self.security_logger = logging.getLogger('security')\n",
    "        self.audit_logger = logging.getLogger('audit')\n",
    "        self.performance_logger = logging.getLogger('performance')\n",
    "    \n",
    "    def log_user_action(self, user_id: str, action: str, resource: str, details: dict = None):\n",
    "        \"\"\"Log user actions for audit trail\"\"\"\n",
    "        audit_entry = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'user_id': user_id,\n",
    "            'action': action,\n",
    "            'resource': resource,\n",
    "            'details': details or {},\n",
    "            'ip_address': details.get('ip_address') if details else None,\n",
    "            'user_agent': details.get('user_agent') if details else None\n",
    "        }\n",
    "        \n",
    "        self.audit_log.append(audit_entry)\n",
    "        \n",
    "        # Maintain audit log size\n",
    "        if len(self.audit_log) > self.max_audit_entries:\n",
    "            self.audit_log = self.audit_log[-self.max_audit_entries:]\n",
    "        \n",
    "        # Log to file\n",
    "        self.audit_logger.info(f\"User action: {json.dumps(audit_entry)}\")\n",
    "    \n",
    "    def log_security_event(self, event_type: str, details: dict):\n",
    "        \"\"\"Log security-related events\"\"\"\n",
    "        security_entry = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'event_type': event_type,\n",
    "            'details': details,\n",
    "            'severity': details.get('severity', 'medium')\n",
    "        }\n",
    "        \n",
    "        self.security_logger.warning(f\"Security event: {json.dumps(security_entry)}\")\n",
    "    \n",
    "    def log_performance_metric(self, metric_name: str, value: float, context: dict = None):\n",
    "        \"\"\"Log performance metrics\"\"\"\n",
    "        perf_entry = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'metric': metric_name,\n",
    "            'value': value,\n",
    "            'context': context or {}\n",
    "        }\n",
    "        \n",
    "        self.performance_logger.info(f\"Performance: {json.dumps(perf_entry)}\")\n",
    "    \n",
    "    def get_audit_trail(self, user_id: str = None, hours: int = 24) -> list:\n",
    "        \"\"\"Get audit trail for specified user and time period\"\"\"\n",
    "        cutoff_time = datetime.now() - timedelta(hours=hours)\n",
    "        \n",
    "        filtered_entries = []\n",
    "        for entry in self.audit_log:\n",
    "            entry_time = datetime.fromisoformat(entry['timestamp'])\n",
    "            \n",
    "            if entry_time >= cutoff_time:\n",
    "                if user_id is None or entry['user_id'] == user_id:\n",
    "                    filtered_entries.append(entry)\n",
    "        \n",
    "        return sorted(filtered_entries, key=lambda x: x['timestamp'], reverse=True)\n",
    "\n",
    "# Initialize logging system\n",
    "logging_system = ProductionLoggingSystem()\n",
    "print(\"✓ Production logging and audit system configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Logging System\n",
    "\n",
    "Test various logging capabilities including audit trails and security events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📝 Testing Logging System...\\n\")\n",
    "\n",
    "# Log user actions\n",
    "logging_system.log_user_action(\n",
    "    user_id=\"admin_001\",\n",
    "    action=\"create_policy\",\n",
    "    resource=\"insurance_policy\",\n",
    "    details={\n",
    "        'ip_address': '192.168.1.100',\n",
    "        'user_agent': 'Mozilla/5.0',\n",
    "        'policy_id': 'POL-12345'\n",
    "    }\n",
    ")\n",
    "print(\"✓ User action logged\")\n",
    "\n",
    "# Log security event\n",
    "logging_system.log_security_event(\n",
    "    event_type=\"failed_login\",\n",
    "    details={\n",
    "        'severity': 'high',\n",
    "        'username': 'unknown_user',\n",
    "        'ip_address': '203.0.113.42',\n",
    "        'attempts': 3\n",
    "    }\n",
    ")\n",
    "print(\"✓ Security event logged\")\n",
    "\n",
    "# Log performance metric\n",
    "logging_system.log_performance_metric(\n",
    "    metric_name=\"query_duration\",\n",
    "    value=0.125,\n",
    "    context={\n",
    "        'query_type': 'read',\n",
    "        'endpoint': '/api/policies'\n",
    "    }\n",
    ")\n",
    "print(\"✓ Performance metric logged\")\n",
    "\n",
    "# Add more test entries\n",
    "for i in range(5):\n",
    "    logging_system.log_user_action(\n",
    "        user_id=f\"user_{i:03d}\",\n",
    "        action=\"view_claims\",\n",
    "        resource=\"claims\",\n",
    "        details={'ip_address': f'192.168.1.{100+i}'}\n",
    "    )\n",
    "\n",
    "print(f\"\\n✅ Logging system operational\")\n",
    "print(f\"📊 Total audit entries: {len(logging_system.audit_log)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Audit Trail\n",
    "\n",
    "Query and display the audit trail for monitoring user activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 Retrieving Audit Trail...\\n\")\n",
    "\n",
    "# Get all recent audit entries\n",
    "recent_audit = logging_system.get_audit_trail(hours=1)\n",
    "\n",
    "print(f\"Recent Audit Entries (last 1 hour): {len(recent_audit)}\\n\")\n",
    "\n",
    "for entry in recent_audit[:5]:  # Show first 5\n",
    "    print(f\"[{entry['timestamp']}]\")\n",
    "    print(f\"  User: {entry['user_id']}\")\n",
    "    print(f\"  Action: {entry['action']}\")\n",
    "    print(f\"  Resource: {entry['resource']}\")\n",
    "    if entry.get('details'):\n",
    "        print(f\"  Details: {entry['details']}\")\n",
    "    print()\n",
    "\n",
    "# Get audit trail for specific user\n",
    "user_audit = logging_system.get_audit_trail(user_id=\"admin_001\", hours=24)\n",
    "print(f\"\\n📋 Audit entries for admin_001: {len(user_audit)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Health Report\n",
    "\n",
    "Create a comprehensive health report combining system and database metrics.\n",
    "\n",
    "**Note:** This requires a Neo4j connection. Update the connection details as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🏥 Generating Health Report...\\n\")\n",
    "\n",
    "if NEO4J_AVAILABLE:\n",
    "    try:\n",
    "        # Connect to Neo4j (update credentials as needed)\n",
    "        driver = GraphDatabase.driver(\n",
    "            \"bolt://localhost:7687\",\n",
    "            auth=(\"neo4j\", \"password\")\n",
    "        )\n",
    "        \n",
    "        # Generate health report\n",
    "        health_report = monitoring_system.generate_health_report(driver)\n",
    "        \n",
    "        print(f\"Overall Health: {health_report['overall_health'].upper()}\")\n",
    "        print(f\"Timestamp: {health_report['timestamp']}\")\n",
    "        \n",
    "        # System metrics\n",
    "        if 'system_metrics' in health_report:\n",
    "            sys_metrics = health_report['system_metrics']\n",
    "            print(f\"\\n🖥️  System Metrics:\")\n",
    "            print(f\"  CPU: {sys_metrics.get('cpu_percent', 0):.2f}%\")\n",
    "            print(f\"  Memory: {sys_metrics.get('memory_percent', 0):.2f}%\")\n",
    "            print(f\"  Disk: {sys_metrics.get('disk_percent', 0):.2f}%\")\n",
    "        \n",
    "        # Database metrics\n",
    "        if 'database_metrics' in health_report:\n",
    "            db_metrics = health_report['database_metrics']\n",
    "            print(f\"\\n🗄️  Database Metrics:\")\n",
    "            print(f\"  Status: {db_metrics.get('database_status', 'unknown')}\")\n",
    "            print(f\"  Response Time: {db_metrics.get('query_response_time', 0)*1000:.2f}ms\")\n",
    "            print(f\"  Nodes: {db_metrics.get('node_count', 0):,}\")\n",
    "            print(f\"  Relationships: {db_metrics.get('relationship_count', 0):,}\")\n",
    "        \n",
    "        # Alerts\n",
    "        if health_report.get('alerts'):\n",
    "            print(f\"\\n🚨 Alerts:\")\n",
    "            for alert in health_report['alerts']:\n",
    "                severity_icon = \"🔴\" if alert['severity'] == 'critical' else \"🟡\"\n",
    "                print(f\"  {severity_icon} {alert['message']}\")\n",
    "        else:\n",
    "            print(f\"\\n✅ No active alerts\")\n",
    "        \n",
    "        driver.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not connect to Neo4j: {e}\")\n",
    "        print(\"Please update connection details or skip this section\")\n",
    "else:\n",
    "    print(\"⚠️ Neo4j driver not available - install neo4j package\")\n",
    "\n",
    "print(\"\\n✅ Health report generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "In this notebook, you've:\n",
    "1. ✅ Implemented production monitoring system with Prometheus\n",
    "2. ✅ Created system metrics collection (CPU, memory, disk)\n",
    "3. ✅ Built Neo4j database metrics monitoring\n",
    "4. ✅ Configured enterprise logging and audit system\n",
    "5. ✅ Generated comprehensive health reports\n",
    "\n",
    "**Monitoring Best Practices:**\n",
    "- Collect metrics at regular intervals (30-60 seconds)\n",
    "- Set appropriate alert thresholds for critical metrics\n",
    "- Maintain audit logs for compliance and security\n",
    "- Use structured logging (JSON) for easier analysis\n",
    "- Implement health checks for all critical components\n",
    "- Monitor both system and application-specific metrics\n",
    "\n",
    "**Next Steps:** Proceed to notebook 04 for Backup and Disaster Recovery implementation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
